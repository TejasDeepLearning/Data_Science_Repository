{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Spam Filter using the Naive Bayes' Algorithm\n",
    "\n",
    "Using a dataset that contains about 5000 spam messages, we're going to build a spam filter using our knowledge on probabilites and the multinomial naive bayes' algorithm. The dataset can be downloaded directly from [here](https://dq-content.s3.amazonaws.com/433/SMSSpamCollection), but you could also download it from this [website](https://archive.ics.uci.edu/ml/datasets/sms+spam+collection)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5572, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms = pd.read_csv('/Users/Tejas/csv_files/SMSSpamCollection', \n",
    "                  sep='\\t', \n",
    "                  header=None, \n",
    "                  names=['Label', 'SMS'])\n",
    "print(sms.shape)\n",
    "sms.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our dataset's \"label\" column, 'ham' means the message is a non-spam message and 'spam' means the message is a spam message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     86.593683\n",
       "spam    13.406317\n",
       "Name: Label, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms['Label'].value_counts(normalize=True) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "About 87% of our messages are not spam and 13% of our messages are spam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1078</th>\n",
       "      <td>ham</td>\n",
       "      <td>Yep, by the pretty sculpture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4028</th>\n",
       "      <td>ham</td>\n",
       "      <td>Yes, princess. Are you going to make me moan?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>958</th>\n",
       "      <td>ham</td>\n",
       "      <td>Welp apparently he retired</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4642</th>\n",
       "      <td>ham</td>\n",
       "      <td>Havent.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4674</th>\n",
       "      <td>ham</td>\n",
       "      <td>I forgot 2 ask ü all smth.. There's a card on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>ham</td>\n",
       "      <td>We're all getting worried over here, derek and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5192</th>\n",
       "      <td>ham</td>\n",
       "      <td>Oh oh... Den muz change plan liao... Go back h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3980</th>\n",
       "      <td>ham</td>\n",
       "      <td>CERI U REBEL! SWEET DREAMZ ME LITTLE BUDDY!! C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>spam</td>\n",
       "      <td>Text &amp; meet someone sexy today. U can find a d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5157</th>\n",
       "      <td>ham</td>\n",
       "      <td>K k:) sms chat with me.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label                                                SMS\n",
       "1078   ham                       Yep, by the pretty sculpture\n",
       "4028   ham      Yes, princess. Are you going to make me moan?\n",
       "958    ham                         Welp apparently he retired\n",
       "4642   ham                                            Havent.\n",
       "4674   ham  I forgot 2 ask ü all smth.. There's a card on ...\n",
       "...    ...                                                ...\n",
       "905    ham  We're all getting worried over here, derek and...\n",
       "5192   ham  Oh oh... Den muz change plan liao... Go back h...\n",
       "3980   ham  CERI U REBEL! SWEET DREAMZ ME LITTLE BUDDY!! C...\n",
       "235   spam  Text & meet someone sexy today. U can find a d...\n",
       "5157   ham                            K k:) sms chat with me.\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms_random = sms.sample(frac=1, random_state=1)\n",
    "sms_random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're going to Split the data into a training and test set to see if our algorithm works on some new data that we provid it, learining from as much data as possible. We are going to split the data as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4458\n",
      "1114\n"
     ]
    }
   ],
   "source": [
    "# 80% for the training data\n",
    "print(round(((80 / 100) * 5572)))\n",
    "\n",
    "#20% for the test data\n",
    "print(round(((20 / 100) * 5572)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = sms_random.iloc[:4458, ]\n",
    "test = sms_random.iloc[4458:, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4458, 2)\n",
      "(1114, 2)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.reset_index(inplace=True, drop=True)\n",
    "test.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Yep, by the pretty sculpture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Yes, princess. Are you going to make me moan?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Welp apparently he retired</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>Havent.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>I forgot 2 ask ü all smth.. There's a card on ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham                       Yep, by the pretty sculpture\n",
       "1   ham      Yes, princess. Are you going to make me moan?\n",
       "2   ham                         Welp apparently he retired\n",
       "3   ham                                            Havent.\n",
       "4   ham  I forgot 2 ask ü all smth.. There's a card on ..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Later i guess. I needa do mcat study too.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>But i haf enuff space got like 4 mb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 10 mths? Update to latest Oran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>All sounds good. Fingers . Makes it difficult ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>All done, all handed in. Don't know if mega sh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham          Later i guess. I needa do mcat study too.\n",
       "1   ham             But i haf enuff space got like 4 mb...\n",
       "2  spam  Had your mobile 10 mths? Update to latest Oran...\n",
       "3   ham  All sounds good. Fingers . Makes it difficult ...\n",
       "4   ham  All done, all handed in. Don't know if mega sh..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we find the percentage of 'ham' and 'spam' in both the training and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     86.54105\n",
       "spam    13.45895\n",
       "Name: Label, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.Label.value_counts(normalize=True) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     86.804309\n",
       "spam    13.195691\n",
       "Name: Label, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.Label.value_counts(normalize=True) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find that the percentages are more or less similar to what we have in the full dataset. With a bit of data cleaning, we're going to make the computer classify messages as spam or not spam by looking at the individual words in each SMS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Secret   Money  goods '"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can use this regular expression to detect any character\n",
    "# that's not from a-z, A-Z or 0-9. \n",
    "re.sub('\\W', ' ', 'Secret!! Money, goods.' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We remove all the punctuation in the SMS column:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>yep  by the pretty sculpture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>yes  princess  are you going to make me moan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>welp apparently he retired</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>havent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>i forgot 2 ask ü all smth   there s a card on ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham                       yep  by the pretty sculpture\n",
       "1   ham      yes  princess  are you going to make me moan \n",
       "2   ham                         welp apparently he retired\n",
       "3   ham                                            havent \n",
       "4   ham  i forgot 2 ask ü all smth   there s a card on ..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['SMS'] = train['SMS'].str.replace('\\W', ' ')\n",
    "train['SMS'] = train['SMS'].str.lower()\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then split the words into a list using the str.split method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>[yep, by, the, pretty, sculpture]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>[yes, princess, are, you, going, to, make, me,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>[welp, apparently, he, retired]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>[havent]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>[i, forgot, 2, ask, ü, all, smth, there, s, a,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham                  [yep, by, the, pretty, sculpture]\n",
       "1   ham  [yes, princess, are, you, going, to, make, me,...\n",
       "2   ham                    [welp, apparently, he, retired]\n",
       "3   ham                                           [havent]\n",
       "4   ham  [i, forgot, 2, ask, ü, all, smth, there, s, a,..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['SMS'] = train['SMS'].str.split()\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a nested loop, we create a vocabulary that contains every unique word in this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = []\n",
    "for word_lists in train.SMS:\n",
    "    for word in word_lists:\n",
    "        vocabulary.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['taunton',\n",
       " 'teaches',\n",
       " '1pm',\n",
       " 'grow',\n",
       " 'salon',\n",
       " 'filling',\n",
       " 'lips',\n",
       " 'nat27081980',\n",
       " 'waz',\n",
       " 'lubly',\n",
       " 'sucks',\n",
       " '09064017305',\n",
       " 'sufficient',\n",
       " 'realised',\n",
       " 'stuffed',\n",
       " 'thk',\n",
       " 'exposed',\n",
       " '09701213186',\n",
       " 'terry',\n",
       " 'reslove',\n",
       " 'jen',\n",
       " 'shijas',\n",
       " 'greet',\n",
       " '08002986030',\n",
       " 'drug',\n",
       " 'mis',\n",
       " 'contract',\n",
       " 'gimme',\n",
       " 'vomiting',\n",
       " 'gibbs',\n",
       " 'wings',\n",
       " 'pixels',\n",
       " 'this',\n",
       " 'confused',\n",
       " 'till',\n",
       " 'ringtones',\n",
       " 'txting',\n",
       " 'msging',\n",
       " 'thia',\n",
       " 'dog',\n",
       " 'tessy',\n",
       " 'meanwhile',\n",
       " '7pm',\n",
       " 'guesses',\n",
       " 'young',\n",
       " 'begun',\n",
       " 'toughest',\n",
       " 'oli',\n",
       " 'wedlunch',\n",
       " 'exams',\n",
       " 'hence',\n",
       " 'helloooo',\n",
       " 'monthlysubscription',\n",
       " 'yck',\n",
       " 'sundayish',\n",
       " 'dooms',\n",
       " 'cc',\n",
       " 'lays',\n",
       " 'ques',\n",
       " 'cake',\n",
       " 'singapore',\n",
       " 'buffet',\n",
       " 'coach',\n",
       " 'unknown',\n",
       " 'answer',\n",
       " 'termsapply',\n",
       " 'calls',\n",
       " 'rofl',\n",
       " 'gumby',\n",
       " '82277',\n",
       " 'real1',\n",
       " 'supposed',\n",
       " 'peach',\n",
       " 'egg',\n",
       " 'thinks',\n",
       " 'fulfil',\n",
       " 'morning',\n",
       " 'chosen',\n",
       " '09065069154',\n",
       " '08715203652',\n",
       " 'pretty',\n",
       " 'trusting',\n",
       " 'box403',\n",
       " 'pray',\n",
       " 'thkin',\n",
       " '20',\n",
       " 'bettersn',\n",
       " 'conveying',\n",
       " 'oh',\n",
       " '3650',\n",
       " 'to',\n",
       " '2bold',\n",
       " 'whens',\n",
       " 'blake',\n",
       " 'arngd',\n",
       " 'skirt',\n",
       " 'os',\n",
       " 'pansy',\n",
       " 'gam',\n",
       " 'ah',\n",
       " 'stamps',\n",
       " 'tensed',\n",
       " 'syd',\n",
       " 'stops',\n",
       " 'names',\n",
       " 'cashto',\n",
       " '10am',\n",
       " 'pete',\n",
       " '2geva',\n",
       " 'scammers',\n",
       " 'arguments',\n",
       " 'bucks',\n",
       " 'sacked',\n",
       " 'sensible',\n",
       " 'urmom',\n",
       " '09056242159',\n",
       " 'lovingly',\n",
       " 'tigress',\n",
       " 'jones',\n",
       " 'tm',\n",
       " 'ertini',\n",
       " 'city',\n",
       " '08701417012150p',\n",
       " 'eating',\n",
       " 'm221bp',\n",
       " 'bhaji',\n",
       " 'sharing',\n",
       " 'investigate',\n",
       " 'txtstop',\n",
       " 'c',\n",
       " 'ice',\n",
       " 'sos',\n",
       " 'fine',\n",
       " 'comp',\n",
       " 'hurt',\n",
       " 'boo',\n",
       " 'cm2',\n",
       " 'fumbling',\n",
       " 'iraq',\n",
       " 'torch',\n",
       " 'hmm',\n",
       " 'skillgame',\n",
       " 'tarot',\n",
       " 'gent',\n",
       " '82050',\n",
       " 'breathe',\n",
       " 'adults',\n",
       " 'strewn',\n",
       " 'reference',\n",
       " 'alle',\n",
       " 'lay',\n",
       " 'revealed',\n",
       " 'bristol',\n",
       " 'quit',\n",
       " 'payee',\n",
       " 'finest',\n",
       " '07734396839',\n",
       " 'dosomething',\n",
       " 'parents',\n",
       " 'much',\n",
       " 'pounds',\n",
       " 'bluetooth',\n",
       " 'fund',\n",
       " '195',\n",
       " 'happened',\n",
       " 'prsn',\n",
       " 'joking',\n",
       " 'fucked',\n",
       " 'cold',\n",
       " 'compliments',\n",
       " 'promptly',\n",
       " 'usc',\n",
       " 'based',\n",
       " 'cd',\n",
       " 'adult',\n",
       " 'straight',\n",
       " 'potato',\n",
       " 'playing',\n",
       " 'local',\n",
       " 'takecare',\n",
       " 'wallpaper',\n",
       " 'career',\n",
       " 'competition',\n",
       " 'yaxx',\n",
       " 'loverboy',\n",
       " '82324',\n",
       " 'plane',\n",
       " 'waiting',\n",
       " 'randy',\n",
       " 'acc',\n",
       " 'thesis',\n",
       " '2morrowxxxx',\n",
       " 'doggin',\n",
       " '09061221061',\n",
       " 'boss',\n",
       " 'angry',\n",
       " 'hearin',\n",
       " 'pink',\n",
       " 'subscribe',\n",
       " '47per',\n",
       " 'gotmarried',\n",
       " 'ts',\n",
       " 'pocy',\n",
       " 'cheque',\n",
       " '21',\n",
       " 'hlday',\n",
       " 'hangin',\n",
       " 'approx',\n",
       " 'stores',\n",
       " 'topic',\n",
       " 'james',\n",
       " 'l',\n",
       " 'delivered',\n",
       " '440',\n",
       " 'oreos',\n",
       " 'bill',\n",
       " 'help',\n",
       " '113',\n",
       " 'secondary',\n",
       " 'publish',\n",
       " 'expired',\n",
       " 'labor',\n",
       " 'bslvyl',\n",
       " 'heal',\n",
       " 'rcd',\n",
       " 'holby',\n",
       " 'challenge',\n",
       " 'facebook',\n",
       " 'sathya',\n",
       " 'gave',\n",
       " 'regalportfolio',\n",
       " 'tenants',\n",
       " 'bcaz',\n",
       " 'lambu',\n",
       " 'macha',\n",
       " 'song',\n",
       " 'asks',\n",
       " 'webeburnin',\n",
       " 'prefer',\n",
       " 'dating',\n",
       " 'bcm1896wc1n3xx',\n",
       " 'subscriptions',\n",
       " 'faith',\n",
       " 'invited',\n",
       " 'tsunami',\n",
       " 'london',\n",
       " 'burnt',\n",
       " 'reserved',\n",
       " 'golden',\n",
       " 'standing',\n",
       " 'p',\n",
       " 'schools',\n",
       " 'choose',\n",
       " 'recharged',\n",
       " 'galileo',\n",
       " 'boggy',\n",
       " 'makin',\n",
       " 'styles',\n",
       " 'ay',\n",
       " 'noline',\n",
       " 'present',\n",
       " 'coat',\n",
       " 'distract',\n",
       " 'trips',\n",
       " 'ystrday',\n",
       " 'watevr',\n",
       " 'snatch',\n",
       " 'refilled',\n",
       " 'linerental',\n",
       " 'tmrw',\n",
       " 'california',\n",
       " 'nanny',\n",
       " 'wer',\n",
       " '12mths',\n",
       " '2years',\n",
       " 'of',\n",
       " 'algebra',\n",
       " 'mobilesdirect',\n",
       " 'k61',\n",
       " 'deliveredtomorrow',\n",
       " 'decided',\n",
       " '89080',\n",
       " 'sculpture',\n",
       " 'bsn',\n",
       " 'congratulation',\n",
       " 'boost',\n",
       " 'skins',\n",
       " 'shouting',\n",
       " 'identification',\n",
       " '2006',\n",
       " 'ahead',\n",
       " 'punish',\n",
       " 'scool',\n",
       " 'vava',\n",
       " 'avatar',\n",
       " 'bfore',\n",
       " 'invention',\n",
       " 'intention',\n",
       " 'skyped',\n",
       " 'fml',\n",
       " '25',\n",
       " '40mph',\n",
       " 'poker',\n",
       " 'wylie',\n",
       " 'hot',\n",
       " 'takes',\n",
       " 'dha',\n",
       " 'boatin',\n",
       " 'cheer',\n",
       " 'saucy',\n",
       " '33',\n",
       " 'h',\n",
       " 'animation',\n",
       " 'poor',\n",
       " 'discount',\n",
       " 'thursday',\n",
       " 'jst',\n",
       " 'greece',\n",
       " 'tho',\n",
       " 'answerin',\n",
       " '28days',\n",
       " 'voda',\n",
       " 'stressfull',\n",
       " 'elections',\n",
       " '07973788240',\n",
       " 'small',\n",
       " 'jos',\n",
       " 'beggar',\n",
       " 'aluable',\n",
       " 'rush',\n",
       " 'bx526',\n",
       " 'goals',\n",
       " 'spoiled',\n",
       " 'logo',\n",
       " 'promoting',\n",
       " 'ship',\n",
       " 'guessed',\n",
       " 'spring',\n",
       " 'recognise',\n",
       " 'pobox365o4w45wq',\n",
       " 'escape',\n",
       " 'eaten',\n",
       " 'forum',\n",
       " 'drop',\n",
       " 'shd',\n",
       " 'cosign',\n",
       " 'pocked',\n",
       " 'dai',\n",
       " 'alrite',\n",
       " 'beendropping',\n",
       " 'seing',\n",
       " 'gods',\n",
       " 'uttered',\n",
       " 'festival',\n",
       " 'mjzgroup',\n",
       " 'lasting',\n",
       " 'roommates',\n",
       " '220',\n",
       " 'mix',\n",
       " 'speeding',\n",
       " 'bak',\n",
       " 'coping',\n",
       " 'mean',\n",
       " 'subscribed',\n",
       " '09066364311',\n",
       " 'messaged',\n",
       " 'quickly',\n",
       " 'surly',\n",
       " 'doit',\n",
       " 'todo',\n",
       " 'stuffing',\n",
       " 'ave',\n",
       " 'enemies',\n",
       " 'goggles',\n",
       " 'mutations',\n",
       " 'urgnt',\n",
       " 'count',\n",
       " 'rats',\n",
       " 'awarded',\n",
       " 'linux',\n",
       " 'power',\n",
       " 'club',\n",
       " 'britney',\n",
       " '69911',\n",
       " 'wrote',\n",
       " '02072069400',\n",
       " 'admirer',\n",
       " 'nyt',\n",
       " 'kisi',\n",
       " 'cudnt',\n",
       " '87575',\n",
       " 'ya',\n",
       " 'australia',\n",
       " 'divorce',\n",
       " 'tel',\n",
       " 'hairdressers',\n",
       " 'enufcredeit',\n",
       " '80122300p',\n",
       " 'costs',\n",
       " 'prevent',\n",
       " 'describe',\n",
       " 'stubborn',\n",
       " 'drunken',\n",
       " 'siguviri',\n",
       " 'cakes',\n",
       " 'prakasam',\n",
       " 'lovin',\n",
       " 'feet',\n",
       " 'user',\n",
       " 'nange',\n",
       " 'phone750',\n",
       " 'world',\n",
       " 'mandan',\n",
       " 'theoretically',\n",
       " 'noon',\n",
       " 'jez',\n",
       " 'colany',\n",
       " 'direct',\n",
       " 'vargu',\n",
       " 'xy',\n",
       " 'raining',\n",
       " 'books',\n",
       " 'hcl',\n",
       " 'matter',\n",
       " 'ors',\n",
       " 'layin',\n",
       " 'envelope',\n",
       " 'quiet',\n",
       " 'certificate',\n",
       " 'rhode',\n",
       " 'cramps',\n",
       " '5years',\n",
       " 'christ',\n",
       " '69101',\n",
       " 'thesedays',\n",
       " 'ceiling',\n",
       " 'b4',\n",
       " '2007',\n",
       " 'require',\n",
       " '08712402902',\n",
       " 'trip',\n",
       " 'bt',\n",
       " 'o2',\n",
       " 'issue',\n",
       " 'trying',\n",
       " 'places',\n",
       " 'cooked',\n",
       " 'baby',\n",
       " 'overa',\n",
       " 'practical',\n",
       " 'bstfrnd',\n",
       " 'tune',\n",
       " 'the4th',\n",
       " 'pound',\n",
       " 'returning',\n",
       " 'lttrs',\n",
       " 'madoke',\n",
       " 'location',\n",
       " 'shb',\n",
       " 'singles',\n",
       " 'melt',\n",
       " 'oranges',\n",
       " 'dust',\n",
       " 'edge',\n",
       " 'education',\n",
       " 'hungry',\n",
       " '24',\n",
       " 'd',\n",
       " 'story',\n",
       " 'these',\n",
       " 'uwana',\n",
       " '23g',\n",
       " 'flew',\n",
       " 'specialisation',\n",
       " 'bf',\n",
       " 'music',\n",
       " '83039',\n",
       " 'gotbabes',\n",
       " 'opposed',\n",
       " 'gone',\n",
       " 'turn',\n",
       " '450',\n",
       " 'baig',\n",
       " 'grumble',\n",
       " '08000839402',\n",
       " 'defo',\n",
       " 'kicks',\n",
       " 'fancies',\n",
       " '3gbp',\n",
       " 'dialogue',\n",
       " 'geoenvironmental',\n",
       " 'tree',\n",
       " '09063442151',\n",
       " 'batsman',\n",
       " 'walking',\n",
       " 'rays',\n",
       " 'pobox45w2tg150p',\n",
       " 'census',\n",
       " 'eight',\n",
       " 'clocks',\n",
       " 'computers',\n",
       " 'percent',\n",
       " 'literally',\n",
       " 'talents',\n",
       " 'anyways',\n",
       " 'scared',\n",
       " 'lovable',\n",
       " 'reminder',\n",
       " 'gym',\n",
       " 'light',\n",
       " '2005',\n",
       " 'pract',\n",
       " 'hmv',\n",
       " 'indicate',\n",
       " '07xxxxxxxxx',\n",
       " 'eleven',\n",
       " 'wipro',\n",
       " 'stitch',\n",
       " 'nighters',\n",
       " 'resubbing',\n",
       " 'fees',\n",
       " 'further',\n",
       " 'colin',\n",
       " 'abuse',\n",
       " 'inshah',\n",
       " 'self',\n",
       " 'gail',\n",
       " 'approaching',\n",
       " 'pura',\n",
       " 'iphone',\n",
       " 'parkin',\n",
       " '09066660100',\n",
       " 'amp',\n",
       " 'resume',\n",
       " 'shelf',\n",
       " 'function',\n",
       " 'penis',\n",
       " 'peril',\n",
       " 'experience',\n",
       " 'camp',\n",
       " '09061743386',\n",
       " 'waitin',\n",
       " 'excuse',\n",
       " 'bergkamp',\n",
       " 'honest',\n",
       " 'failing',\n",
       " 'nat',\n",
       " 'arsenal',\n",
       " 'or2stoptxt',\n",
       " 'lets',\n",
       " 'cutie',\n",
       " 'dramatic',\n",
       " 'espe',\n",
       " 'x49',\n",
       " 'raglan',\n",
       " '09064012160',\n",
       " 'becomes',\n",
       " 'waqt',\n",
       " 'fa',\n",
       " 'welcome',\n",
       " 'gudnyt',\n",
       " 'feels',\n",
       " 'stash',\n",
       " 'all',\n",
       " 'remembered',\n",
       " 'nearer',\n",
       " '1',\n",
       " 'role',\n",
       " 'glo',\n",
       " 'alfie',\n",
       " 'ready',\n",
       " 'desparate',\n",
       " 'following',\n",
       " 'art',\n",
       " 'informed',\n",
       " '24hrs',\n",
       " 'get4an18th',\n",
       " 'max10mins',\n",
       " 'area',\n",
       " 'closingdate04',\n",
       " 'woken',\n",
       " 'f',\n",
       " '75max',\n",
       " 'audrie',\n",
       " 'draw',\n",
       " 'signin',\n",
       " 'unemployed',\n",
       " 'fatty',\n",
       " 'dun',\n",
       " 'padhe',\n",
       " 'supervisor',\n",
       " 'sexiest',\n",
       " 'latest',\n",
       " 'cs',\n",
       " 'fish',\n",
       " 'smarter',\n",
       " 'newport',\n",
       " 'oclock',\n",
       " 'm8',\n",
       " 'sen',\n",
       " 'feelin',\n",
       " 'optout',\n",
       " 'bloke',\n",
       " 'maximum',\n",
       " 'types',\n",
       " 'ctagg',\n",
       " 'cine',\n",
       " 'point',\n",
       " 'er',\n",
       " 'lionp',\n",
       " 'moved',\n",
       " 'display',\n",
       " 'blonde',\n",
       " '0871212025016',\n",
       " 'revision',\n",
       " 'ended',\n",
       " 'idps',\n",
       " 'disagreeable',\n",
       " 'buff',\n",
       " 'repeat',\n",
       " 'dsn',\n",
       " 'privacy',\n",
       " 'eachother',\n",
       " 'compromised',\n",
       " '300',\n",
       " 'ppm150',\n",
       " 'presnts',\n",
       " 'freemsg',\n",
       " '07090201529',\n",
       " 'fridge',\n",
       " '2nd',\n",
       " 'ugadi',\n",
       " 'clarification',\n",
       " 'vouchers',\n",
       " 'shola',\n",
       " 'filthyguys',\n",
       " 'idu',\n",
       " 'warned',\n",
       " 'ptbo',\n",
       " 'coccooning',\n",
       " 'foreign',\n",
       " '2814032',\n",
       " 'space',\n",
       " 'irritated',\n",
       " 'dual',\n",
       " 'babies',\n",
       " 'every1',\n",
       " 'vu',\n",
       " 'dryer',\n",
       " '861',\n",
       " 'recorder',\n",
       " 'ordered',\n",
       " 'countin',\n",
       " 'tming',\n",
       " 'realising',\n",
       " 'slurp',\n",
       " 'boyfriend',\n",
       " 'limiting',\n",
       " 'full',\n",
       " 'files',\n",
       " 'shoving',\n",
       " 'spanish',\n",
       " 'comin',\n",
       " 'ear',\n",
       " 'chez',\n",
       " 'lookatme',\n",
       " 'breaker',\n",
       " 'monoc',\n",
       " 'hospital',\n",
       " 'twice',\n",
       " '9996',\n",
       " 'mustprovide',\n",
       " 'traditions',\n",
       " 'drinks',\n",
       " 'snappy',\n",
       " 'ans',\n",
       " 'cnupdates',\n",
       " 'while',\n",
       " '930',\n",
       " 'web',\n",
       " 'kickoff',\n",
       " 'imat',\n",
       " 'impressed',\n",
       " 'vegas',\n",
       " 'fgkslpopw',\n",
       " '30th',\n",
       " 'england',\n",
       " 'mk45',\n",
       " 'cheyyamo',\n",
       " 'staying',\n",
       " 'mudyadhu',\n",
       " 'ivatte',\n",
       " 'deserve',\n",
       " '3ss',\n",
       " 'clothes',\n",
       " 'sn',\n",
       " 'pocay',\n",
       " 'goverment',\n",
       " 'bcm',\n",
       " 'onto',\n",
       " 'yijue',\n",
       " '09058095107',\n",
       " '87077',\n",
       " 'campus',\n",
       " 'phone',\n",
       " 'u',\n",
       " 'less',\n",
       " 'christmas',\n",
       " 'freek',\n",
       " 'leanne',\n",
       " 'himself',\n",
       " 'hw',\n",
       " 'lol',\n",
       " 'host',\n",
       " 'unconvinced',\n",
       " 'durban',\n",
       " '81151',\n",
       " 'market',\n",
       " 'future',\n",
       " 'delayed',\n",
       " 'unlimited',\n",
       " 'cbe',\n",
       " '900',\n",
       " 'raji',\n",
       " 'shld',\n",
       " 'food',\n",
       " 'hillsborough',\n",
       " 'teenager',\n",
       " 'tobacco',\n",
       " 'suntec',\n",
       " 'ref',\n",
       " '2i',\n",
       " 'appy',\n",
       " 'situation',\n",
       " 'someday',\n",
       " 'exam',\n",
       " '1st',\n",
       " 'magic',\n",
       " 'earth',\n",
       " 'erotic',\n",
       " '09065174042',\n",
       " 'sez',\n",
       " '09057039994',\n",
       " 'ta',\n",
       " 'it',\n",
       " 'deleted',\n",
       " 'charged',\n",
       " 'donate',\n",
       " 'proper',\n",
       " 'gpu',\n",
       " 'arab',\n",
       " 'ktv',\n",
       " 'wrnog',\n",
       " 'dunno',\n",
       " 'illness',\n",
       " 'gaytextbuddy',\n",
       " 'last',\n",
       " 'anal',\n",
       " 'lighters',\n",
       " 'old',\n",
       " 'babyjontet',\n",
       " 'slip',\n",
       " 'always',\n",
       " 'agidhane',\n",
       " 'dub',\n",
       " 'harish',\n",
       " 'passionate',\n",
       " 'outs',\n",
       " 'mom',\n",
       " '850',\n",
       " 'hmph',\n",
       " 'shame',\n",
       " 'fathima',\n",
       " 'rejected',\n",
       " 'server',\n",
       " 'buttheres',\n",
       " 'meaningful',\n",
       " 'mistakes',\n",
       " 'ripped',\n",
       " 'bye',\n",
       " 'deus',\n",
       " 'chase',\n",
       " 'nri',\n",
       " 'loss',\n",
       " 'soon',\n",
       " '7732584351',\n",
       " 'sorrows',\n",
       " 'hole',\n",
       " 'needing',\n",
       " 'maneesha',\n",
       " 'careers',\n",
       " 'avin',\n",
       " 'mandy',\n",
       " '2000',\n",
       " 'washob',\n",
       " 'secrets',\n",
       " 'eg',\n",
       " 'comes',\n",
       " 'clear',\n",
       " 'mtmsg',\n",
       " 'needy',\n",
       " 'poop',\n",
       " '08707500020',\n",
       " 'strings',\n",
       " 'mon',\n",
       " 'tkls',\n",
       " 'bat',\n",
       " 'call09050000327',\n",
       " 'nos',\n",
       " 'telephone',\n",
       " 'pest',\n",
       " '09064012103',\n",
       " 'covers',\n",
       " 'lanre',\n",
       " 'himso',\n",
       " 'murderer',\n",
       " 'appt',\n",
       " 'ringtoneking',\n",
       " 'ccna',\n",
       " 'netvision',\n",
       " 'wannatell',\n",
       " 'parent',\n",
       " 'lodge',\n",
       " '087187262701',\n",
       " 'three',\n",
       " 'classes',\n",
       " 'noworriesloans',\n",
       " 'lose',\n",
       " 'mas',\n",
       " 'wocay',\n",
       " 'apeshit',\n",
       " 'sex',\n",
       " 'conform',\n",
       " 'whoever',\n",
       " 'easy',\n",
       " '3days',\n",
       " 'spot',\n",
       " 'yoga',\n",
       " 'slovely',\n",
       " 'bad',\n",
       " 'chechi',\n",
       " 'fuckinnice',\n",
       " 'pure',\n",
       " 'andrews',\n",
       " 'deposited',\n",
       " 'evry1',\n",
       " 'paranoid',\n",
       " 'pause',\n",
       " 'guy',\n",
       " '0870',\n",
       " 'joined',\n",
       " 'callon',\n",
       " '09066362206',\n",
       " 'aries',\n",
       " 'destiny',\n",
       " 've',\n",
       " 'bell',\n",
       " 'bit',\n",
       " 'able',\n",
       " 'little',\n",
       " 'shall',\n",
       " 'ambrith',\n",
       " 'helpline',\n",
       " 'astne',\n",
       " 'when',\n",
       " 'randomly',\n",
       " 'sleepin',\n",
       " 'balls',\n",
       " 'meals',\n",
       " 'though',\n",
       " 'incorrect',\n",
       " 'setting',\n",
       " 'aint',\n",
       " 'up4',\n",
       " 'non',\n",
       " 'wa14',\n",
       " 'cochin',\n",
       " '09065989182',\n",
       " 'bb',\n",
       " 'anderson',\n",
       " 'sachin',\n",
       " 'lingerie',\n",
       " 'birds',\n",
       " 'expression',\n",
       " 'two',\n",
       " 'dates',\n",
       " 'pictures',\n",
       " 'double',\n",
       " 'motivate',\n",
       " 'callcost150ppmmobilesvary',\n",
       " 'nightnight',\n",
       " 'guild',\n",
       " 'traveling',\n",
       " 'dt',\n",
       " 'crucify',\n",
       " 'poo',\n",
       " 'handed',\n",
       " 'creep',\n",
       " 'calculated',\n",
       " 'nr31',\n",
       " 'hotel',\n",
       " '07801543489',\n",
       " 'zeros',\n",
       " 'faggot',\n",
       " 'amount',\n",
       " 'flute',\n",
       " 'thew',\n",
       " 'working',\n",
       " 'shoppin',\n",
       " 'ree',\n",
       " 'seperated',\n",
       " 'asssssholeeee',\n",
       " 'broadband',\n",
       " 'reboot',\n",
       " 'ps',\n",
       " 'packs',\n",
       " '_',\n",
       " 'unintentional',\n",
       " '60p',\n",
       " 'fed',\n",
       " 'oreo',\n",
       " 'firsg',\n",
       " 'witot',\n",
       " 'jeevithathile',\n",
       " 'modl',\n",
       " 'dump',\n",
       " 'balloon',\n",
       " 'ip4',\n",
       " 'ú1',\n",
       " 'lock',\n",
       " 'blessed',\n",
       " 'onlyfound',\n",
       " 'cheesy',\n",
       " 'gimmi',\n",
       " 'opened',\n",
       " 'mcfly',\n",
       " 'margaret',\n",
       " '83383',\n",
       " 'perform',\n",
       " 'la32wu',\n",
       " 'send',\n",
       " '6th',\n",
       " 'raiden',\n",
       " 'fifa',\n",
       " 'prizeswith',\n",
       " 'glands',\n",
       " 'celebration',\n",
       " 'na',\n",
       " 'asshole',\n",
       " 'why',\n",
       " 'ldn',\n",
       " 'cricketer',\n",
       " 'tasts',\n",
       " 'won',\n",
       " 'busy',\n",
       " 'pooja',\n",
       " 'goto',\n",
       " 'happenin',\n",
       " 'left',\n",
       " '87239',\n",
       " 'listening',\n",
       " 'massive',\n",
       " 'coins',\n",
       " 'den',\n",
       " 'pleasant',\n",
       " 'platt',\n",
       " 'determined',\n",
       " 'children',\n",
       " 'kilos',\n",
       " 'hehe',\n",
       " '08718738034',\n",
       " '6hrs',\n",
       " 'snowboarding',\n",
       " 'projects',\n",
       " 'youuuuu',\n",
       " 'normal',\n",
       " 'posts',\n",
       " 'telugu',\n",
       " 'wtlp',\n",
       " 'bills',\n",
       " 'askin',\n",
       " 'auction',\n",
       " 'watchin',\n",
       " '3xx',\n",
       " '80488',\n",
       " '09066649731from',\n",
       " 'sterm',\n",
       " 'kothi',\n",
       " 'ms',\n",
       " 'released',\n",
       " 'baaaaabe',\n",
       " 'swayze',\n",
       " 'hypotheticalhuagauahahuagahyuhagga',\n",
       " 'isaiah',\n",
       " 'gek1510',\n",
       " 'guess',\n",
       " 'rowdy',\n",
       " 'woul',\n",
       " 'place',\n",
       " 'transfered',\n",
       " ...]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary = set(vocabulary)\n",
    "vocabulary = list(vocabulary)\n",
    "vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7783"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a dataframe that contains each unique word in the column and the number of times we see that word for each spam and non spam message in the data, we first create a dictionary that counts the number of words in the data and then transform that dictionary into a dataframe and join that dataframe with the training set so that we have our Label and SMS column for reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts_per_sms = {unique_word: [0] * len(train['SMS']) for unique_word in vocabulary}\n",
    "\n",
    "for index, sms in enumerate(train['SMS']):\n",
    "    for word in sms:\n",
    "        word_counts_per_sms[word][index] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>taunton</th>\n",
       "      <th>teaches</th>\n",
       "      <th>1pm</th>\n",
       "      <th>grow</th>\n",
       "      <th>salon</th>\n",
       "      <th>filling</th>\n",
       "      <th>lips</th>\n",
       "      <th>nat27081980</th>\n",
       "      <th>...</th>\n",
       "      <th>dnt</th>\n",
       "      <th>cheap</th>\n",
       "      <th>63miles</th>\n",
       "      <th>hotmail</th>\n",
       "      <th>plum</th>\n",
       "      <th>purity</th>\n",
       "      <th>bid</th>\n",
       "      <th>disastrous</th>\n",
       "      <th>tom</th>\n",
       "      <th>oja</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>[yep, by, the, pretty, sculpture]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>[yes, princess, are, you, going, to, make, me,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>[welp, apparently, he, retired]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>[havent]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>[i, forgot, 2, ask, ü, all, smth, there, s, a,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS  taunton  teaches  \\\n",
       "0   ham                  [yep, by, the, pretty, sculpture]        0        0   \n",
       "1   ham  [yes, princess, are, you, going, to, make, me,...        0        0   \n",
       "2   ham                    [welp, apparently, he, retired]        0        0   \n",
       "3   ham                                           [havent]        0        0   \n",
       "4   ham  [i, forgot, 2, ask, ü, all, smth, there, s, a,...        0        0   \n",
       "\n",
       "   1pm  grow  salon  filling  lips  nat27081980  ...  dnt  cheap  63miles  \\\n",
       "0    0     0      0        0     0            0  ...    0      0        0   \n",
       "1    0     0      0        0     0            0  ...    0      0        0   \n",
       "2    0     0      0        0     0            0  ...    0      0        0   \n",
       "3    0     0      0        0     0            0  ...    0      0        0   \n",
       "4    0     0      0        0     0            0  ...    0      0        0   \n",
       "\n",
       "   hotmail  plum  purity  bid  disastrous  tom  oja  \n",
       "0        0     0       0    0           0    0    0  \n",
       "1        0     0       0    0           0    0    0  \n",
       "2        0     0       0    0           0    0    0  \n",
       "3        0     0       0    0           0    0    0  \n",
       "4        0     0       0    0           0    0    0  \n",
       "\n",
       "[5 rows x 7785 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts = pd.DataFrame(word_counts_per_sms)\n",
    "train_clean = pd.concat([train, word_counts], axis=1)\n",
    "train_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>taunton</th>\n",
       "      <th>teaches</th>\n",
       "      <th>1pm</th>\n",
       "      <th>grow</th>\n",
       "      <th>salon</th>\n",
       "      <th>filling</th>\n",
       "      <th>lips</th>\n",
       "      <th>nat27081980</th>\n",
       "      <th>waz</th>\n",
       "      <th>lubly</th>\n",
       "      <th>...</th>\n",
       "      <th>dnt</th>\n",
       "      <th>cheap</th>\n",
       "      <th>63miles</th>\n",
       "      <th>hotmail</th>\n",
       "      <th>plum</th>\n",
       "      <th>purity</th>\n",
       "      <th>bid</th>\n",
       "      <th>disastrous</th>\n",
       "      <th>tom</th>\n",
       "      <th>oja</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7783 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   taunton  teaches  1pm  grow  salon  filling  lips  nat27081980  waz  lubly  \\\n",
       "0        0        0    0     0      0        0     0            0    0      0   \n",
       "1        0        0    0     0      0        0     0            0    0      0   \n",
       "2        0        0    0     0      0        0     0            0    0      0   \n",
       "3        0        0    0     0      0        0     0            0    0      0   \n",
       "4        0        0    0     0      0        0     0            0    0      0   \n",
       "\n",
       "   ...  dnt  cheap  63miles  hotmail  plum  purity  bid  disastrous  tom  oja  \n",
       "0  ...    0      0        0        0     0       0    0           0    0    0  \n",
       "1  ...    0      0        0        0     0       0    0           0    0    0  \n",
       "2  ...    0      0        0        0     0       0    0           0    0    0  \n",
       "3  ...    0      0        0        0     0       0    0           0    0    0  \n",
       "4  ...    0      0        0        0     0       0    0           0    0    0  \n",
       "\n",
       "[5 rows x 7783 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're going to calculate all the necessary probability values and number of instances observed to insert into our Naive Bayes algorithm.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_msgs = train_clean[train_clean['Label'] == 'spam']\n",
    "ham_msgs = train_clean[train_clean['Label'] == 'ham']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_spam = len(spam_msgs) / len(train_clean)\n",
    "p_spam\n",
    "p_ham = len(ham_msgs) / len(train_clean)\n",
    "p_ham\n",
    "\n",
    "n_words_per_spam_message = spam_msgs['SMS'].apply(len)\n",
    "n_spam = n_words_per_spam_message.sum()\n",
    "\n",
    "n_words_per_ham_message = ham_msgs['SMS'].apply(len)\n",
    "n_ham = n_words_per_ham_message.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_vocabulary = len(vocabulary) \n",
    "alpha = 1 #additive smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We initialize two dictionaries that are going to be used to count the number of times a word occurs in both spam and ham messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_dict_spam = {unique_word:0 for unique_word in vocabulary}\n",
    "word_dict_ham = {unique_word:0 for unique_word in vocabulary}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we calculate the probability of getting that messgae in a spam and ham."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in vocabulary:\n",
    "    n_word_given_spam = spam_msgs[word].sum()\n",
    "    p_word_given_spam = (n_word_given_spam + alpha) / (n_spam + alpha * n_vocabulary)\n",
    "    \n",
    "    n_word_given_ham = ham_msgs[word].sum()\n",
    "    p_word_given_ham = (n_word_given_ham + alpha) / (n_ham + alpha * n_vocabulary)\n",
    "    \n",
    "    word_dict_spam[word] = p_word_given_spam\n",
    "    word_dict_ham[word] = p_word_given_ham"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then create a function to compare the probabilities of getting a spam given we got some message and getting a ham given we got some message and then decide whether the message is a spam or not a spam based on the probabilities found. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(message):\n",
    "\n",
    "    message = re.sub('\\W', ' ', message)\n",
    "    message = message.lower()\n",
    "    message = message.split()\n",
    "    \n",
    "    p_spam_given_message = p_spam\n",
    "    p_ham_given_message = p_ham\n",
    "    \n",
    "    for word in message:\n",
    "        if word in word_dict_spam:\n",
    "            p_spam_given_message *= word_dict_spam[word]\n",
    "        if word in word_dict_ham:\n",
    "            p_ham_given_message *= word_dict_ham[word]\n",
    "\n",
    "    print('P(Spam|message):', p_spam_given_message)\n",
    "    print('P(Ham|message):', p_ham_given_message)\n",
    "\n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        print('Label: Ham')\n",
    "    elif p_ham_given_message < p_spam_given_message:\n",
    "        print('Label: Spam')\n",
    "    else:\n",
    "        print('Equal proabilities, have a human classify this!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Spam|message): 1.3481290211300841e-25\n",
      "P(Ham|message): 1.9368049028589875e-27\n",
      "Label: Spam\n"
     ]
    }
   ],
   "source": [
    "classify('WINNER!! This is the secret code to unlock the money: C3421.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Spam|message): 2.4372375665888117e-25\n",
      "P(Ham|message): 3.687530435009238e-21\n",
      "Label: Ham\n"
     ]
    }
   ],
   "source": [
    "classify(\"Sounds good, Tom, then see u there\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use this function on our test set. We change the print statements to return statements as we need to apply this function to our test set in order for it to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_test_set(message):\n",
    "\n",
    "    message = re.sub('\\W', ' ', message)\n",
    "    message = message.lower()\n",
    "    message = message.split()\n",
    "\n",
    "    p_spam_given_message = p_spam\n",
    "    p_ham_given_message = p_ham\n",
    "\n",
    "    for word in message:\n",
    "        if word in word_dict_spam:\n",
    "            p_spam_given_message *= word_dict_spam[word]\n",
    "\n",
    "        if word in word_dict_ham:\n",
    "            p_ham_given_message *= word_dict_ham[word]\n",
    "\n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        return 'ham'\n",
    "    elif p_spam_given_message > p_ham_given_message:\n",
    "        return 'spam'\n",
    "    else:\n",
    "        return 'needs human classification'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Later i guess. I needa do mcat study too.</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>But i haf enuff space got like 4 mb...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 10 mths? Update to latest Oran...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>All sounds good. Fingers . Makes it difficult ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>All done, all handed in. Don't know if mega sh...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS predicted\n",
       "0   ham          Later i guess. I needa do mcat study too.       ham\n",
       "1   ham             But i haf enuff space got like 4 mb...       ham\n",
       "2  spam  Had your mobile 10 mths? Update to latest Oran...      spam\n",
       "3   ham  All sounds good. Fingers . Makes it difficult ...       ham\n",
       "4   ham  All done, all handed in. Don't know if mega sh...       ham"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['predicted'] = test['SMS'].apply(classify_test_set)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can measure the accuracy (the metric we use to calculate the amount of correct predictions the function made on our test set) to see if our function performed better or worse than what we expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9874326750448833"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct = 0\n",
    "total = len(test)\n",
    "for msgs in test.iterrows():\n",
    "    msgs = msgs[1]\n",
    "    if msgs.Label == msgs.predicted:\n",
    "        correct += 1\n",
    "        \n",
    "accuracy = correct / total\n",
    "accuracy\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98.74326750448833"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like we got an accuracy of 98.74%. This is good, and shows us that our spam filter can be used to check other messages to see whether they are spam or not. This concludes the project, thank you for reading."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
